{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning and Validation\n",
    "\n",
    "This is the first in a series of notebooks that make up a [case study in exploratory data analysis](https://allendowney.github.io/PoliticalAlignmentCaseStudy/). This case study is part of the [Elements of Data Science](https://allendowney.github.io/ElementsOfDataScience/) curriculum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this notebook, we:\n",
    "\n",
    "1. Read data from the General Social Survey (GSS),\n",
    "2. Clean the data, particularly dealing with special codes that indicate missing data,\n",
    "3. Validate the data by comparing the values in the dataset with values documented in the codebook.\n",
    "4. Generate resampled datasets that correct for deliberate oversampling in the dataset, and\n",
    "5. Store the resampled data in a binary format (HDF5) that makes it easier to work with in the notebooks that follow this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data\n",
    "\n",
    "The data we'll use is from the General Social Survey (GSS). Using the [GSS Data Explorer](https://gssdataexplorer.norc.org), A subset of the variables in the GSS were selected and made  available along with this notebook. The following cell loads this extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72390, 207)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gss = pd.read_hdf(\"../data/gss_pacs_2022.hdf\", \"gss\")\n",
    "gss.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `head` to see what the `DataFrame` looks like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abany</th>\n",
       "      <th>abdefect</th>\n",
       "      <th>abhlth</th>\n",
       "      <th>abnomore</th>\n",
       "      <th>abpoor</th>\n",
       "      <th>abrape</th>\n",
       "      <th>absingle</th>\n",
       "      <th>acqntsex</th>\n",
       "      <th>adults</th>\n",
       "      <th>affrmact</th>\n",
       "      <th>...</th>\n",
       "      <th>trdunion</th>\n",
       "      <th>trust</th>\n",
       "      <th>union</th>\n",
       "      <th>wkharsex</th>\n",
       "      <th>wkracism</th>\n",
       "      <th>wksexism</th>\n",
       "      <th>wtssall</th>\n",
       "      <th>wtssps</th>\n",
       "      <th>xmarsex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4446</td>\n",
       "      <td>0.663196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8893</td>\n",
       "      <td>0.917370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8893</td>\n",
       "      <td>0.897413</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8893</td>\n",
       "      <td>1.066341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.8893</td>\n",
       "      <td>0.944324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abany  abdefect  abhlth  abnomore  abpoor  abrape  absingle  acqntsex  \\\n",
       "0    NaN       1.0     1.0       1.0     1.0     1.0       1.0       NaN   \n",
       "1    NaN       1.0     1.0       2.0     2.0     1.0       1.0       NaN   \n",
       "2    NaN       1.0     1.0       1.0     1.0     1.0       1.0       NaN   \n",
       "3    NaN       2.0     1.0       2.0     1.0     1.0       1.0       NaN   \n",
       "4    NaN       1.0     1.0       1.0     1.0     1.0       1.0       NaN   \n",
       "\n",
       "   adults  affrmact  ...  trdunion  trust  union  wkharsex  wkracism  \\\n",
       "0     1.0       NaN  ...       NaN    3.0    NaN       NaN       NaN   \n",
       "1     2.0       NaN  ...       NaN    1.0    NaN       NaN       NaN   \n",
       "2     2.0       NaN  ...       NaN    2.0    NaN       NaN       NaN   \n",
       "3     2.0       NaN  ...       NaN    2.0    NaN       NaN       NaN   \n",
       "4     2.0       NaN  ...       NaN    2.0    NaN       NaN       NaN   \n",
       "\n",
       "   wksexism  wtssall    wtssps  xmarsex  year  \n",
       "0       NaN   0.4446  0.663196      NaN  1972  \n",
       "1       NaN   0.8893  0.917370      NaN  1972  \n",
       "2       NaN   0.8893  0.897413      NaN  1972  \n",
       "3       NaN   0.8893  1.066341      NaN  1972  \n",
       "4       NaN   0.8893  0.944324      NaN  1972  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gss.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has 72390 rows, one for each respondent, and 207 columns, one for each variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "\n",
    "Now that we've got the data loaded, it is important to validate it, which means checking for errors. The kinds of errors you have to check for depend on the nature of the data, the collection process, how the data is stored and transmitted, etc. For this dataset, there are three kinds of validation we'll think about:\n",
    "\n",
    "1. We need to check the **integrity** of the dataset; that is, whether the data were corrupted or changed during transmission, storage, or conversion from one format to another.\n",
    "2. We need to check our **interpretation** of the data; for example, whether the numbers used to encode the data mean what we think they mean.\n",
    "3. We will also keep an eye out for **invalid** data; for example, missing data might be represented using special codes, or there might be patterns in the data that indicate problems with the survey process and the recording of the data.\n",
    "\n",
    "In a different dataset I worked with, I found a surprising number of respondents whose height was supposedly 62 centimeters. After investigating, I concluded that they were probably 6 feet, 2 inches, and their heights were recorded incorrectly. Validating data can be a tedious process, but it is important. If you interpret data incorrectly and publish invalid results, you will be embarrassed in the best case, and in the worst case you might do real harm.\n",
    "\n",
    "The first variable we'll validate is called polviews. It records responses to the following question:\n",
    "> We hear a lot of talk these days about liberals and conservatives. I'm going to show you a seven-point scale on which the political views that people might hold are arranged from extremely liberal--point 1--to extremely conservative--point 7. Where would you place yourself on this scale?\n",
    "\n",
    "You can read the documentation of this variable in the [GSS codebook](https://gssdataexplorer.norc.org/variables/178/vshow). The responses are encoded like this:\n",
    "\n",
    "|   |                        |\n",
    "|---|------------------------|\n",
    "| 1 | Extremely liberal      |\n",
    "| 2 | Liberal                |\n",
    "| 3 | Slightly liberal       |\n",
    "| 4 | Moderate               |\n",
    "| 5 | Slghtly conservative   |\n",
    "| 6 | Conservative           |\n",
    "| 7 | Extremely conservative |\n",
    "| 8 | Don't know             |\n",
    "| 9 | No answer              |\n",
    "| 0 | Not applicable         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function, `values`, takes a Series that represents a single variable and returns the values in the series and their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def values(series):\n",
    "    \"\"\"Count the values and sort.\n",
    "\n",
    "    series: pd.Series\n",
    "\n",
    "    returns: series mapping from values to frequencies\n",
    "    \"\"\"\n",
    "    return series.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the values for the variable `polviews`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polviews\n",
       "1.0     2081\n",
       "2.0     7623\n",
       "3.0     7900\n",
       "4.0    23992\n",
       "5.0     9596\n",
       "6.0     9361\n",
       "7.0     2165\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polviews = gss[\"polviews\"]\n",
    "values(polviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the integrity of the data and confirm that we have loaded it correctly, we'll do a \"spot check\"; that is, we'll pick one year and compare the values we see in the dataset to the values reported in the codebook.\n",
    "\n",
    "We can select values from a single year like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polviews\n",
       "1.0     22\n",
       "2.0    201\n",
       "3.0    207\n",
       "4.0    564\n",
       "5.0    221\n",
       "6.0    160\n",
       "7.0     35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_year = gss[\"year\"] == 1974\n",
    "values(polviews[one_year])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you compare these results to the [values in the codebook](https://gssdataexplorer.norc.org/variables/178/vshow), you should see that they agree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data\n",
    "\n",
    "For many variables, missing values are encoded with numerical codes that we need to replace before we do any analysis. For `polviews`, the values 8, 9, and 0 represent \"Don't know\", \"No answer\", and \"Not applicable\". \"Not applicable\" usually means the respondent was not asked a particular question.\n",
    "\n",
    "To keep things simple, we'll treat all of these values as equivalent, but we lose some information by doing that. For example, if a respondent refuses to answer a question, that might suggest something about their answer. If so, treating their response as missing data might bias the results. Fortunately, for most questions the number of respondents who refused to answer is small. I'll replace the numeric codes 8, 9, and 0 with `np.nan`, which is a special value used to indicate missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        NaN\n",
       "1        NaN\n",
       "2        NaN\n",
       "3        NaN\n",
       "4        NaN\n",
       "        ... \n",
       "72385    1.0\n",
       "72386    4.0\n",
       "72387    3.0\n",
       "72388    3.0\n",
       "72389    2.0\n",
       "Name: polviews, Length: 72390, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NA = np.nan\n",
    "clean = polviews.replace([0, 8, 9], NA)\n",
    "clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `np.nan` is displayed, it appears as `NaN`, which stands for \"not a number\". We can use `notna` and `sum` to count the valid responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62718\n"
     ]
    }
   ],
   "source": [
    "valid_responses_count = clean.notna().sum()\n",
    "print(valid_responses_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we use isna to count the missing responses:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9672\n"
     ]
    }
   ],
   "source": [
    "missing_responses_count = clean.isna().sum()\n",
    "print(missing_responses_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing missing data\n",
    "\n",
    "For the other variables in this dataset, I read through the code book and identified the special values that indicate missing data. I recorded that information in the following function, which is intended to replace special values with `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_invalid(df, columns, bad):\n",
    "    for column in columns:\n",
    "        df.replace({column: NA}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gss_replace_invalid(df):\n",
    "    \"\"\"Replace invalid data with NaN.\n",
    "\n",
    "    df: DataFrame\n",
    "    \"\"\"\n",
    "    # different variables use different codes for invalid data\n",
    "    df.replace({\"cohort\": NA}, inplace=True)\n",
    "\n",
    "    # since there are a lot of variables that use 0, 8, and 9 for invalid data,\n",
    "    # I'll use a loop to replace all of them\n",
    "    columns = [\n",
    "        \"abany\",\n",
    "        \"abdefect\",\n",
    "        \"abhlth\",\n",
    "        \"abnomore\",\n",
    "        \"abpoor\",\n",
    "        \"abrape\",\n",
    "        \"absingle\",\n",
    "        \"acqntsex\",\n",
    "        \"affrmact\",\n",
    "        \"bible\",\n",
    "        \"cappun\",\n",
    "        \"colath\",\n",
    "        \"colcom\",\n",
    "        \"colhomo\",\n",
    "        \"colmil\",\n",
    "        \"colmslm\",\n",
    "        \"colrac\",\n",
    "        \"colsoc\",\n",
    "        \"compuse\",\n",
    "        \"conarmy\",\n",
    "        \"conbus\",\n",
    "        \"conclerg\",\n",
    "        \"coneduc\",\n",
    "        \"confed\",\n",
    "        \"confinan\",\n",
    "        \"conjudge\",\n",
    "        \"conlabor\",\n",
    "        \"conlegis\",\n",
    "        \"conmedic\",\n",
    "        \"conpress\",\n",
    "        \"consci\",\n",
    "        \"contv\",\n",
    "        \"databank\",\n",
    "        \"discaffm\",\n",
    "        \"discaffw\",\n",
    "        \"divlaw\",\n",
    "        \"divorce\",\n",
    "        \"eqwlth\",\n",
    "        \"fair\",\n",
    "        \"fear\",\n",
    "        \"fechld\",\n",
    "        \"fefam\",\n",
    "        \"fehelp\",\n",
    "        \"fehire\",\n",
    "        \"fehome\",\n",
    "        \"fejobaff\",\n",
    "        \"fepol\",\n",
    "        \"fepres\",\n",
    "        \"fepresch\",\n",
    "        \"fework\",\n",
    "        \"finrela\",\n",
    "        \"frndsex\",\n",
    "        \"fund\",\n",
    "        \"god\",\n",
    "        \"goodlife\",\n",
    "        \"grass\",\n",
    "        \"gunlaw\",\n",
    "        \"hapmar\",\n",
    "        \"happy\",\n",
    "        \"health\",\n",
    "        \"helpful\",\n",
    "        \"hhrace\",\n",
    "        \"homosex\",\n",
    "        \"hunt\",\n",
    "        \"libath\",\n",
    "        \"libcom\",\n",
    "        \"libhomo\",\n",
    "        \"libmil\",\n",
    "        \"libmslm\",\n",
    "        \"librac\",\n",
    "        \"libsoc\",\n",
    "        \"life\",\n",
    "        \"matesex\",\n",
    "        \"meovrwrk\",\n",
    "        \"miracles\",\n",
    "        \"nataid\",\n",
    "        \"natarms\",\n",
    "        \"natchld\",\n",
    "        \"natcity\",\n",
    "        \"natcrime\",\n",
    "        \"natdrug\",\n",
    "        \"nateduc\",\n",
    "        \"natenrgy\",\n",
    "        \"natenvir\",\n",
    "        \"natfare\",\n",
    "        \"natheal\",\n",
    "        \"natmass\",\n",
    "        \"natpark\",\n",
    "        \"natrace\",\n",
    "        \"natroad\",\n",
    "        \"natsci\",\n",
    "        \"natsoc\",\n",
    "        \"natspac\",\n",
    "        \"othersex\",\n",
    "        \"paidsex\",\n",
    "        \"pikupsex\",\n",
    "        \"polabuse\",\n",
    "        \"polattak\",\n",
    "        \"polescap\",\n",
    "        \"polhitok\",\n",
    "        \"polmurdr\",\n",
    "        \"polviews\",\n",
    "        \"popespks\",\n",
    "        \"pornlaw\",\n",
    "        \"postlife\",\n",
    "        \"pray\",\n",
    "        \"prayer\",\n",
    "        \"premarsx\",\n",
    "        \"pres00\",\n",
    "        \"pres04\",\n",
    "        \"pres08\",\n",
    "        \"pres12\",\n",
    "        \"pres96\",\n",
    "        \"racchurh\",\n",
    "        \"racclos\",\n",
    "        \"racdif1\",\n",
    "        \"racdif2\",\n",
    "        \"racdif3\",\n",
    "        \"racdif4\",\n",
    "        \"racdin\",\n",
    "        \"racdis\",\n",
    "        \"racfew\",\n",
    "        \"rachaf\",\n",
    "        \"rachome\",\n",
    "        \"racinteg\",\n",
    "        \"raclive\",\n",
    "        \"racmar\",\n",
    "        \"racmost\",\n",
    "        \"racopen\",\n",
    "        \"racpres\",\n",
    "        \"racpush\",\n",
    "        \"racschol\",\n",
    "        \"racseg\",\n",
    "        \"racwork\",\n",
    "        \"reborn\",\n",
    "        \"relexp\",\n",
    "        \"relexper\",\n",
    "        \"reliten\",\n",
    "        \"relpersn\",\n",
    "        \"res16\",\n",
    "        \"rowngun\",\n",
    "        \"satfin\",\n",
    "        \"satjob\",\n",
    "        \"savesoul\",\n",
    "        \"sexbirth\",\n",
    "        \"sexeduc\",\n",
    "        \"sexnow\",\n",
    "        \"sexornt\",\n",
    "        \"sexsex\",\n",
    "        \"sexsex5\",\n",
    "        \"spanking\",\n",
    "        \"spkath\",\n",
    "        \"spkcom\",\n",
    "        \"spkhomo\",\n",
    "        \"spklang\",\n",
    "        \"spkmil\",\n",
    "        \"spkmslm\",\n",
    "        \"spkrac\",\n",
    "        \"spksoc\",\n",
    "        \"sprtprsn\",\n",
    "        \"teensex\",\n",
    "        \"trdunion\",\n",
    "        \"trust\",\n",
    "        \"union\",\n",
    "        \"wkharsex\",\n",
    "        \"wkracism\",\n",
    "        \"wksexism\",\n",
    "        \"xmarsex\",\n",
    "        \"commun\",\n",
    "    ]\n",
    "    replace_invalid(df, columns, [0, 8, 9])\n",
    "\n",
    "    columns = [\"degree\", \"partyid\"]\n",
    "    replace_invalid(df, columns, [8, 9])\n",
    "\n",
    "    df[\"phone\"] = df[\"phone\"].replace([0, 2, 9], NA)\n",
    "    df[\"owngun\"] = df[\"owngun\"].replace([0, 3, 8, 9], NA)\n",
    "    df[\"pistol\"] = df[\"pistol\"].replace([0, 3, 8, 9], NA)\n",
    "    df[\"class\"] = df[\"class\"].replace([0, 5, 8, 9], NA)\n",
    "\n",
    "    df[\"chldidel\"] = df[\"chldidel\"].replace([-1, 8, 9], NA)\n",
    "    df[\"sexfreq\"] = df[\"sexfreq\"].replace([-1, 8, 9], NA)\n",
    "\n",
    "    df[\"attend\"] = df[\"attend\"].replace([9], NA)\n",
    "    df[\"childs\"] = df[\"childs\"].replace([9], NA)\n",
    "    df[\"adults\"] = df[\"adults\"].replace([9], NA)\n",
    "\n",
    "    df[\"age\"] = df[\"age\"].replace([0, 98, 99], NA)\n",
    "    df[\"relig\"] = df[\"relig\"].replace([0, 98, 99], NA)\n",
    "    df[\"relig16\"] = df[\"relig16\"].replace([0, 98, 99], NA)\n",
    "    df[\"relactiv\"] = df[\"relactiv\"].replace([0, 98, 99], NA)\n",
    "\n",
    "    # note: sibs contains some unlikely numbers\n",
    "    df[\"sibs\"] = df[\"sibs\"].replace([-1, 98, 99], NA)\n",
    "    df[\"hrsrelax\"] = df[\"hrsrelax\"].replace([-1, 98, 99], NA)\n",
    "\n",
    "    df[\"educ\"] = df[\"educ\"].replace([97, 98, 99], NA)\n",
    "\n",
    "    df[\"realinc\"] = df[\"realinc\"].replace([0], NA)\n",
    "    df[\"realrinc\"] = df[\"realrinc\"].replace([0], NA)\n",
    "\n",
    "    df[\"income\"] = df[\"income\"].replace([0, 13, 98, 99], NA)\n",
    "    df[\"rincome\"] = df[\"rincome\"].replace([0, 13, 98, 99], NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss_replace_invalid(gss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# check that we've cleaned all columns that need it;\n",
    "# all columns we've added NaN to should be floats\n",
    "\n",
    "# some columns have no missing values\n",
    "clean_columns = [\"id\", \"year\", \"ballot\", \"sex\", \"race\", \"reg16\", \"region\", \"srcbelt\"]\n",
    "\n",
    "for column in gss.columns:\n",
    "    if gss[column].dtype == int and column not in clean_columns:\n",
    "        print(f\"'{column}', \", end=\"\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "\n",
    "The GSS uses stratified sampling, which means that some groups are deliberately oversampled to help with statistical validity. As a result, each respondent has a sampling weight which is proportional to the number of people in the population they represent.\n",
    "\n",
    "Before running any analysis, we can compensate for stratified sampling by \"resampling\", that is, by drawing a random sample from the dataset, where each respondent's chance of appearing in the sample is proportional to their sampling weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_rows_weighted(df, column):\n",
    "    \"\"\"Resamples a DataFrame using probabilities proportional to given column.\n",
    "\n",
    "    df: DataFrame\n",
    "    column: string column name to use as weights\n",
    "\n",
    "    returns: DataFrame\n",
    "    \"\"\"\n",
    "    weights = df[column]\n",
    "    sample = df.sample(n=len(df), replace=True, weights=weights)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_by_year(df, column):\n",
    "    \"\"\"Resample rows within each year.\n",
    "\n",
    "    df: DataFrame\n",
    "    column: string name of weight variable\n",
    "\n",
    "    returns DataFrame\n",
    "    \"\"\"\n",
    "    grouped = df.groupby(\"year\")\n",
    "    samples = [resample_rows_weighted(group, column) for _, group in grouped]\n",
    "    sample = pd.concat(samples, ignore_index=True)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(19)\n",
    "sample = resample_by_year(gss, \"wtssall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the results\n",
    "\n",
    "I'll save the results to an HDF5 file, which is a binary format that makes it much faster to read the data back. An HDF5 file is like a dictionary on disk. It contains keys and corresponding values. The `to_hdf` method takes three arguments: The filename, `gss_pacs_clean.hdf`; The key, `gss`; And the compression level, which controls how hard the algorithm works to compress the file.\n",
    "\n",
    "So this file contains a single key, `gss`, which maps to the DataFrame with the original GSS data. The argument `w` says that if the file already exists, we should overwrite it. With compression level `6`, it reduces the size of the file by a factor of more than 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/gss_pacs_2022_resampled.hdf\n"
     ]
    }
   ],
   "source": [
    "# if the file already exists, remove it\n",
    "from pathlib import Path\n",
    "\n",
    "if Path.is_file(Path(\"../data/gss_pacs_2022_clean.hdf\")):\n",
    "    ! rm -v ../data/gss_pacs_2022_resampled.hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the original\n",
    "\n",
    "gss.to_hdf(\"../data/gss_pacs_2022_clean.hdf\", key=\"gss\", mode=\"w\", complevel=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 wilderbarbosagalvao  staff    10M Aug 22 18:32 ../data/gss_pacs_2022_clean.hdf\n"
     ]
    }
   ],
   "source": [
    "! ls -lh ../data/gss_pacs_2022_clean.hdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And I'll create a second file with three random resamplings of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate and store three resamplings\n",
    "keys = [\"gss0\", \"gss1\", \"gss2\"]\n",
    "\n",
    "for i in range(3):\n",
    "    np.random.seed(i)\n",
    "    sample = resample_by_year(gss, \"wtssall\")\n",
    "    sample.to_hdf(\"../data/gss_pacs_2022_resampled.hdf\", key=keys[i], complevel=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r--  1 wilderbarbosagalvao  staff    31M Aug 22 18:32 ../data/gss_pacs_2022_resampled.hdf\n"
     ]
    }
   ],
   "source": [
    "! ls -lh ../data/gss_pacs_2022_resampled.hdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the other notebooks in this case study, we'll load this resampled data rather than reading and cleaning the data every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "political-alignment-case-study-OPQ1sBGm-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
